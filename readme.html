<!DOCTYPE html>
<html>
<head>
    <title>Exercise 3 - Introduction to computer graphics</title>
    <style>
        body {
            background-color: #101010;
            color: #F0F0F0;
            font-family: Helvetica;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
            padding: 10px;
        }

        h1 {
            background-color: #F0F0F0;
            color: #101010;
            padding: 10px;
            text-align: center;
        }

        h2 {
            margin-top: 1.5em;
        }

        .center {
            text-align: center;
        }

        img {
            box-shadow: 0px 0px 15px white;
            -webkit-border-radius: 10px;
            -moz-border-radius: 10px;
            border-radius: 10px;
        }
    </style>
</head>

<body>
<h1>Introduction to computer graphics</h1>
<p>
by Amos Wenger and Javier Martín de Valmaseda
</p>
<h2>3.1 Introduction</h2>

<p>Not much to say here, except that we added ostream overloading to Vector2, Vector3, Vector4 and Matrix4 to make it easier to debug.</p>

<h2>3.2 Transformation and Translation (15 points)</h2>

<p>It was really not clear from the slides what to do in getScreenExtents() but we finally figured it out.</p>

<p class='center'><img src="images/figure3-2.png"></p>

<p></p>

<h3>2.1.2 Diffuse Lighting Model</h3>
<p>
It was a simple matter of applying the formula. Getting rid of the case when light ray and normal point are in opposite directions is as simple as verifying that (N dot L) >= 0. Indeed, cos(theta) will be negative if abs(theta) > pi/2

<p class='center'><img src="images/diffuse.png"></p>

<h3>2.1.3 Phong Lighting Model</h3>

<p>
At first we had problems: we were doing scene->getCamera()->getPosition() - iData->sourcePosition for V.. and then we later realized that we should have been doing iData->sourcePosition - iData->position.
</p>

<p class='center'><img src="images/phong.png"></p>

<p>
Apart from that, nothing too hard. Didn't use the course's formula to compute R, just did a bit of thinking, projections, subtractions etc. and ended up simplifying and stumbling upon the same formula :)
</p>

<h2>2.2 Ray Tracing</h2>

<h3>2.2.1 Shadows</h3>
<p>
Implementing the getNonOccludedLights required to cast rays from the light source's position and the given points - if there is an intersection then it's occluded, otherwise it's non-occluded. 
So it was necessary to change the Scene::fastIntersect method to check this condition.
</p>

<p class='center'><img src="images/shadows.png"></p>

<p>
Verifying that the intersection is between the light source and the occluded point is as simple as checking that t = intersectionPos dot rayNormal is bigger than ray's min_t and smaller than ray's max_t.
</p>

<h3>2.2.2 Additional Intersection Information for Recursion</h3>
<p>
Assigning m_reflectionPercentage to iData was enough.
</p>

<h3>2.2.3 Reflection</h3>
<p>
It's necessary to calculate the reflected ray, R, and then calculate the color of the point by the given formula, taking into account the recursion.
As stated in the statement, it's necessary to fix the min_t of the ray with epsilon_t for avoid the shadow ray blocked by self-intersection
</p>

Here's a rendering of InfiniteRoom with reflection set to 0

<p class='center'><img src="images/reflection-0.png"></p>

Here's one with reflection set to 1

<p class='center'><img src="images/reflection-1.png"></p>

Here's one with reflection set to 3

<p class='center'><img src="images/reflection-3.png"></p>

Here's one with reflection set to 8

<p class='center'><img src="images/reflection-8.png"></p>

Here's one with reflection set to 24. As you can see, it's not much use to go beyond 8 :) Was just curious.

<p class='center'><img src="images/reflection-24.png"></p>

<h2>2.3 Final rendering</h2>

<h3>2.2.3 Render a Bigger Mesh</h3>

<p class='center'><img src="images/cornell.png"></p>

It took 416.242 seconds to render (on Windows XP running inside VirtualBox running on Mac OSX 10.7 on a 15" MacBook)

</body>
</html>

